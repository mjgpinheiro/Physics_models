{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa8z4j/7DrW+QHS+nXU3Fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgpinheiro/Physics_models/blob/main/Forex_Price_Prediction_with_LSTM_and_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQU_6jO4wTi",
        "outputId": "313bb852-b473-48e4-b653-28a8f16fa872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.10/dist-packages (0.3.14b0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandas_ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pandas_ta) (1.16.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.28)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.3)\n",
            "Requirement already satisfied: cmaes>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-08-28 20:47:38,826] A new study created in memory with name: no-name-28434c2c-ae42-469c-b38a-9a930837b825\n",
            "[I 2023-08-28 20:49:26,885] Trial 0 finished with value: 0.002494402229785919 and parameters: {'learning_rate': 0.00012906015402951772, 'batch_size': 128, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 0 with value: 0.002494402229785919.\n",
            "[I 2023-08-28 20:53:46,025] Trial 1 finished with value: 0.00029523370903916657 and parameters: {'learning_rate': 0.0005609535011247337, 'batch_size': 64, 'lstm_units': 80, 'dropout_rate': 0.30000000000000004}. Best is trial 1 with value: 0.00029523370903916657.\n",
            "[I 2023-08-28 20:57:16,111] Trial 2 finished with value: 0.0003992709389422089 and parameters: {'learning_rate': 0.0001450620032159825, 'batch_size': 128, 'lstm_units': 80, 'dropout_rate': 0.5}. Best is trial 1 with value: 0.00029523370903916657.\n",
            "[I 2023-08-28 20:59:14,617] Trial 3 finished with value: 0.022772466763854027 and parameters: {'learning_rate': 1.6185631358174995e-05, 'batch_size': 128, 'lstm_units': 50, 'dropout_rate': 0.4}. Best is trial 1 with value: 0.00029523370903916657.\n",
            "[I 2023-08-28 21:01:06,685] Trial 4 finished with value: 0.0003105879295617342 and parameters: {'learning_rate': 0.001293263380753033, 'batch_size': 128, 'lstm_units': 50, 'dropout_rate': 0.30000000000000004}. Best is trial 1 with value: 0.00029523370903916657.\n",
            "[I 2023-08-28 21:04:31,034] Trial 5 finished with value: 0.0004502570955082774 and parameters: {'learning_rate': 0.0005237724168815216, 'batch_size': 128, 'lstm_units': 80, 'dropout_rate': 0.5}. Best is trial 1 with value: 0.00029523370903916657.\n",
            "[I 2023-08-28 21:10:42,478] Trial 6 finished with value: 0.00019920457270927727 and parameters: {'learning_rate': 0.0006314848005673346, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 6 with value: 0.00019920457270927727.\n",
            "[I 2023-08-28 21:14:11,886] Trial 7 finished with value: 0.0015055709518492222 and parameters: {'learning_rate': 2.3298559968779854e-05, 'batch_size': 32, 'lstm_units': 30, 'dropout_rate': 0.1}. Best is trial 6 with value: 0.00019920457270927727.\n",
            "[I 2023-08-28 21:16:50,678] Trial 8 finished with value: 0.0009072966640815139 and parameters: {'learning_rate': 0.007217711112815545, 'batch_size': 64, 'lstm_units': 50, 'dropout_rate': 0.5}. Best is trial 6 with value: 0.00019920457270927727.\n",
            "[I 2023-08-28 21:18:01,822] Trial 9 finished with value: 0.0015707170823588967 and parameters: {'learning_rate': 9.661369821573691e-05, 'batch_size': 128, 'lstm_units': 30, 'dropout_rate': 0.5}. Best is trial 6 with value: 0.00019920457270927727.\n",
            "[I 2023-08-28 21:24:35,499] Trial 10 finished with value: 0.00019109455752186477 and parameters: {'learning_rate': 0.002544228117730047, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 10 with value: 0.00019109455752186477.\n",
            "[I 2023-08-28 21:29:30,862] Trial 11 finished with value: 0.00011353426816640422 and parameters: {'learning_rate': 0.0023692685315957695, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 11 with value: 0.00011353426816640422.\n",
            "[I 2023-08-28 21:34:53,670] Trial 12 finished with value: 0.00016094298916868865 and parameters: {'learning_rate': 0.003296083557902942, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 11 with value: 0.00011353426816640422.\n",
            "[I 2023-08-28 21:40:05,818] Trial 13 finished with value: 9.785777365323156e-05 and parameters: {'learning_rate': 0.008619943206886924, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 21:46:21,568] Trial 14 finished with value: 0.0001870551786851138 and parameters: {'learning_rate': 0.00940546432328669, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 21:51:29,512] Trial 15 finished with value: 0.00027391387266106904 and parameters: {'learning_rate': 0.003988125956651365, 'batch_size': 16, 'lstm_units': 30, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 21:55:12,934] Trial 16 finished with value: 0.000282250257441774 and parameters: {'learning_rate': 0.0017538267176550179, 'batch_size': 32, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:01:46,314] Trial 17 finished with value: 0.0008240517345257103 and parameters: {'learning_rate': 0.009969774323081179, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:08:26,506] Trial 18 finished with value: 0.00019594375044107437 and parameters: {'learning_rate': 0.0041369285638407, 'batch_size': 16, 'lstm_units': 80, 'dropout_rate': 0.4}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:13:36,926] Trial 19 finished with value: 0.0008544582524336874 and parameters: {'learning_rate': 0.001571654078352017, 'batch_size': 16, 'lstm_units': 30, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:15:46,444] Trial 20 finished with value: 0.0006559166358783841 and parameters: {'learning_rate': 0.006419555483389823, 'batch_size': 64, 'lstm_units': 50, 'dropout_rate': 0.30000000000000004}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:22:03,363] Trial 21 finished with value: 0.00023620780848432332 and parameters: {'learning_rate': 0.004429789547009338, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:28:19,240] Trial 22 finished with value: 0.00029352871933951974 and parameters: {'learning_rate': 0.00286193835381025, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:34:34,048] Trial 23 finished with value: 0.0002463493146933615 and parameters: {'learning_rate': 0.0010790083748481788, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:38:05,349] Trial 24 finished with value: 0.0003192285366822034 and parameters: {'learning_rate': 0.0025822657154689265, 'batch_size': 32, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:44:19,028] Trial 25 finished with value: 0.0012798943789675832 and parameters: {'learning_rate': 0.005227159591372353, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:50:52,742] Trial 26 finished with value: 0.00018499940051697195 and parameters: {'learning_rate': 0.006510376043388784, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 22:56:45,330] Trial 27 finished with value: 0.0005690433317795396 and parameters: {'learning_rate': 0.0030439831026424177, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 23:01:46,887] Trial 28 finished with value: 0.0017187414923682809 and parameters: {'learning_rate': 0.009604698905092891, 'batch_size': 16, 'lstm_units': 30, 'dropout_rate': 0.4}. Best is trial 13 with value: 9.785777365323156e-05.\n",
            "[I 2023-08-28 23:07:00,633] Trial 29 finished with value: 0.00019977751071564853 and parameters: {'learning_rate': 0.0021603946399590935, 'batch_size': 64, 'lstm_units': 80, 'dropout_rate': 0.2}. Best is trial 13 with value: 9.785777365323156e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'learning_rate': 0.008619943206886924, 'batch_size': 16, 'lstm_units': 50, 'dropout_rate': 0.1}\n",
            "Epoch 1/10\n",
            "173/173 [==============================] - 16s 68ms/step - loss: 0.0087\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 12s 68ms/step - loss: 0.0022\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 12s 71ms/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 12s 68ms/step - loss: 0.0015\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 12s 71ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 12s 68ms/step - loss: 9.0417e-04\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 11s 65ms/step - loss: 8.2522e-04\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 12s 72ms/step - loss: 7.1226e-04\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 12s 71ms/step - loss: 8.9683e-04\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 12s 71ms/step - loss: 6.4481e-04\n",
            "Epoch 1/10\n",
            "87/87 [==============================] - 6s 71ms/step - loss: 6.1811e-04\n",
            "Epoch 2/10\n",
            "87/87 [==============================] - 7s 79ms/step - loss: 5.4158e-04\n",
            "Epoch 3/10\n",
            "87/87 [==============================] - 6s 64ms/step - loss: 5.1584e-04\n",
            "Epoch 4/10\n",
            "87/87 [==============================] - 7s 82ms/step - loss: 4.9927e-04\n",
            "Epoch 5/10\n",
            "87/87 [==============================] - 6s 66ms/step - loss: 5.8837e-04\n",
            "Epoch 6/10\n",
            "87/87 [==============================] - 7s 81ms/step - loss: 5.6858e-04\n",
            "Epoch 7/10\n",
            "87/87 [==============================] - 6s 64ms/step - loss: 4.5939e-04\n",
            "Epoch 8/10\n",
            "87/87 [==============================] - 7s 80ms/step - loss: 4.3553e-04\n",
            "Epoch 9/10\n",
            "87/87 [==============================] - 6s 65ms/step - loss: 4.8708e-04\n",
            "Epoch 10/10\n",
            "87/87 [==============================] - 7s 81ms/step - loss: 4.8893e-04\n",
            "21/21 [==============================] - 1s 19ms/step\n",
            "Mean Squared Error: 0.00010667080526789653\n",
            "Mean Absolute Error: 0.00817643358608989\n",
            "Mean Squared Error: 0.00010667080526789653\n",
            "Mean Absolute Error: 0.00817643358608989\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted price for the next day: 0.13849506\n",
            "Action: Buy\n",
            "\n",
            "Baseline Model:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "\n",
            "LSTM Model:\n",
            "MSE: 0.00010667080526789617\n",
            "MAE: 0.008176433586089875\n",
            "\n",
            "Conclusion: The baseline model's performance is better than the LSTM model. Caution advised.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "!pip install pandas_ta\n",
        "!pip install yfinance\n",
        "!pip install optuna\n",
        "\n",
        "import optuna\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import pandas_ta as ta\n",
        "\n",
        "# Gather Data\n",
        "symbol = \"AUDUSD=X\"\n",
        "start_date = \"2010-01-01\"\n",
        "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "df = yf.download(symbol, start=start_date, end=end_date, interval=\"1d\")\n",
        "\n",
        "# Calculate technical indicators\n",
        "df[\"RSI\"] = ta.rsi(df[\"Close\"])\n",
        "df[[\"MACD_12_26\", \"MACD_12_26_Signal\", \"MACD_12_26_Hist\"]] = ta.macd(df[\"Close\"])\n",
        "df[\"ATR\"] = ta.atr(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
        "\n",
        "# Drop NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Preprocess Data\n",
        "df_scaler = MinMaxScaler()\n",
        "input_features = [\"Close\", \"RSI\", \"MACD_12_26\", \"MACD_12_26_Signal\", \"MACD_12_26_Hist\", \"ATR\"]\n",
        "df[input_features] = df_scaler.fit_transform(df[input_features])\n",
        "\n",
        "close_scaler = MinMaxScaler()\n",
        "df['Close'] = close_scaler.fit_transform(df[['Close']])\n",
        "\n",
        "# Reset index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Split Data\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df[:train_size]\n",
        "test_data = df[train_size:]\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(data) - seq_length - 1):\n",
        "        sequence = data[i : i + seq_length].values\n",
        "        label = data[\"Close\"].iloc[i + seq_length]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "seq_length = 60\n",
        "train_x, train_y = create_sequences(train_data[input_features], seq_length)\n",
        "test_x, test_y = create_sequences(test_data[input_features], seq_length)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "    lstm_units = trial.suggest_categorical(\"lstm_units\", [30, 50, 80])\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "\n",
        "    # Model definition\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=lstm_units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mean_squared_error\")\n",
        "\n",
        "    # TimeSeriesSplit\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "    for train_index, val_index in tscv.split(train_x):\n",
        "        train_x_cv, val_x_cv = train_x[train_index], train_x[val_index]\n",
        "        train_y_cv, val_y_cv = train_y[train_index], train_y[val_index]\n",
        "\n",
        "        model.fit(train_x_cv, train_y_cv, epochs=10, batch_size=batch_size, validation_data=(val_x_cv, val_y_cv), verbose=0)\n",
        "\n",
        "    val_loss = model.evaluate(val_x_cv, val_y_cv, verbose=0)\n",
        "    return val_loss\n",
        "\n",
        "# Optuna study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "\n",
        "# Training the model with best hyperparameters on full data\n",
        "best_params = study.best_params\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=best_params[\"lstm_units\"], return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
        "model.add(Dropout(best_params[\"dropout_rate\"]))\n",
        "model.add(LSTM(units=best_params[\"lstm_units\"]))\n",
        "model.add(Dropout(best_params[\"dropout_rate\"]))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"]), loss=\"mean_squared_error\")\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=best_params[\"batch_size\"])\n",
        "\n",
        "# ... (Rest of the code remains the same, for predictions, evaluations, etc.)\n",
        "\n",
        "\n",
        "# Train Model\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=32)\n",
        "\n",
        "# Make Predictions\n",
        "predictions = model.predict(test_x)\n",
        "predictions = close_scaler.inverse_transform(predictions)\n",
        "\n",
        "# Evaluate Model\n",
        "mse = mean_squared_error(predictions, close_scaler.inverse_transform(test_y.reshape(-1, 1)))\n",
        "mae = mean_absolute_error(predictions, close_scaler.inverse_transform(test_y.reshape(-1, 1)))\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Save Model\n",
        "model.save(\"forex_trading_bot_model.keras\")\n",
        "\n",
        "# Make a prediction for the next day\n",
        "next_day_sequence = np.expand_dims(test_x[-1], axis=0)\n",
        "next_day_prediction = model.predict(next_day_sequence)\n",
        "next_day_price = close_scaler.inverse_transform(next_day_prediction)[0][0]\n",
        "\n",
        "# Print the predicted price for the next day\n",
        "print(\"Predicted price for the next day:\", next_day_price)\n",
        "\n",
        "# Determine the action based on the predicted price\n",
        "if next_day_price > df[\"Close\"].iloc[-1]:\n",
        "    print(\"Action: Buy\")\n",
        "elif next_day_price < df[\"Close\"].iloc[-1]:\n",
        "    print(\"Action: Sell\")\n",
        "else:\n",
        "    print(\"Action: Hold\")\n",
        "\n",
        "# Create a baseline model that predicts the last known price as the next day's price\n",
        "baseline_predictions = np.roll(test_x[:,-1,0], -1)  # Shift the last known prices one step forward\n",
        "baseline_mse = mean_squared_error(test_y[:-1], baseline_predictions[:-1])\n",
        "baseline_mae = mean_absolute_error(test_y[:-1], baseline_predictions[:-1])\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) and Mean Absolute Error (MAE) for the LSTM model\n",
        "lstm_mse = mean_squared_error(test_y, predictions)\n",
        "lstm_mae = mean_absolute_error(test_y, predictions)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"\\nBaseline Model:\")\n",
        "print(\"MSE:\", baseline_mse)\n",
        "print(\"MAE:\", baseline_mae)\n",
        "\n",
        "print(\"\\nLSTM Model:\")\n",
        "print(\"MSE:\", lstm_mse)\n",
        "print(\"MAE:\", lstm_mae)\n",
        "\n",
        "# Compare the LSTM model's performance with the baseline model's performance\n",
        "if lstm_mse < baseline_mse and lstm_mae < baseline_mae:\n",
        "    print(\"\\nConclusion: The LSTM model's performance is better than the baseline model. Consider using LSTM predictions for trading forex.\")\n",
        "    if next_day_price > df[\"Close\"].iloc[-1]:\n",
        "        print(\"Action: Buy\")\n",
        "    elif next_day_price < df[\"Close\"].iloc[-1]:\n",
        "        print(\"Action: Sell\")\n",
        "    else:\n",
        "        print(\"Action: Hold\")\n",
        "elif lstm_mse > baseline_mse and lstm_mae > baseline_mae:\n",
        "    print(\"\\nConclusion: The baseline model's performance is better than the LSTM model. Caution advised.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: The LSTM model's performance is similar to the baseline model. Use additional analysis for decision-making.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Forex Analysis and Prediction using LSTM and Optuna\n",
        "\n",
        "This notebook employs a deep learning approach to forecast forex prices using Long Short-Term Memory (LSTM) networks, a type of recurrent neural network that's well-suited for sequence prediction problems. The notebook's functionality can be broken down as follows:\n",
        "\n",
        "Data Collection:\n",
        "\n",
        "The notebook fetches historical forex data for a given currency pair (e.g., AUDUSD) from Yahoo Finance, spanning from the beginning of 2010 to the present day.\n",
        "Feature Engineering:\n",
        "\n",
        "It calculates multiple technical indicators, such as the Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), and Average True Range (ATR), which serve as additional features for the model.\n",
        "Data Preprocessing:\n",
        "\n",
        "The forex data, along with the technical indicators, are scaled using a MinMaxScaler for better model performance.\n",
        "It splits the data into training and testing sets.\n",
        "Model Building and Training:\n",
        "\n",
        "An LSTM-based neural network model is constructed. This type of model can capture the temporal relationships in time series data, making it particularly suited for forex price prediction.\n",
        "The model is trained on the historical data.\n",
        "Evaluation:\n",
        "\n",
        "The trained model's predictions on test data are evaluated against actual prices using Mean Squared Error (MSE) and Mean Absolute Error (MAE) metrics.\n",
        "A baseline model, which predicts the last known price as the next day's price, is also evaluated. This helps in gauging the LSTM model's performance relative to a simple prediction strategy.\n",
        "Hyperparameter Tuning and Cross-Validation:\n",
        "\n",
        "The notebook integrates the TimeSeriesSplit method to perform time series cross-validation, ensuring that the model is validated on different segments of the dataset.\n",
        "Optuna, a hyperparameter optimization framework, is employed to search for optimal parameters like learning rate, batch size, LSTM units, etc., aiming to enhance the model's performance.\n",
        "Action Recommendation:\n",
        "\n",
        "Based on the LSTM model's prediction for the next day's price and the most recent known price, the notebook suggests a trading action: Buy, Sell, or Hold.\n",
        "Conclusion:\n",
        "\n",
        "The notebook concludes by comparing the LSTM model's performance against the baseline model, advising the user on the best model to consider for forex trading decisions."
      ],
      "metadata": {
        "id": "mtNMeolkfUbJ"
      }
    }
  ]
}