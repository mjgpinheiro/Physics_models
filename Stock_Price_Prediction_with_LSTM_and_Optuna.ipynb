{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTyNKIIHwX8MRGEfvLPwSK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgpinheiro/Physics_models/blob/main/Stock_Price_Prediction_with_LSTM_and_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huDZwD7pf52d"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "!pip install pandas_ta\n",
        "!pip install yfinance\n",
        "!pip install optuna\n",
        "\n",
        "import optuna\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import pandas_ta as ta\n",
        "\n",
        "# Gather Data\n",
        "ticker = \"AAPL\"  # Apple Inc. stock as an example, can replace with other stock tickers\n",
        "start_date = \"2010-01-01\"\n",
        "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "# Calculate technical indicators\n",
        "df[\"RSI\"] = ta.rsi(df[\"Close\"])\n",
        "df[[\"MACD_12_26\", \"MACD_12_26_Signal\", \"MACD_12_26_Hist\"]] = ta.macd(df[\"Close\"])\n",
        "df[\"ATR\"] = ta.atr(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
        "\n",
        "# Drop NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Preprocess Data\n",
        "df_scaler = MinMaxScaler()\n",
        "input_features = [\"Close\", \"RSI\", \"MACD_12_26\", \"MACD_12_26_Signal\", \"MACD_12_26_Hist\", \"ATR\"]\n",
        "df[input_features] = df_scaler.fit_transform(df[input_features])\n",
        "\n",
        "close_scaler = MinMaxScaler()\n",
        "df['Close'] = close_scaler.fit_transform(df[['Close']])\n",
        "\n",
        "# Reset index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Split Data\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df[:train_size]\n",
        "test_data = df[train_size:]\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(data) - seq_length - 1):\n",
        "        sequence = data[i : i + seq_length].values\n",
        "        label = data[\"Close\"].iloc[i + seq_length]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "seq_length = 60\n",
        "train_x, train_y = create_sequences(train_data[input_features], seq_length)\n",
        "test_x, test_y = create_sequences(test_data[input_features], seq_length)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "    lstm_units = trial.suggest_categorical(\"lstm_units\", [30, 50, 80])\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "\n",
        "    # Model definition\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=lstm_units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mean_squared_error\")\n",
        "\n",
        "    # TimeSeriesSplit\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "    for train_index, val_index in tscv.split(train_x):\n",
        "        train_x_cv, val_x_cv = train_x[train_index], train_x[val_index]\n",
        "        train_y_cv, val_y_cv = train_y[train_index], train_y[val_index]\n",
        "\n",
        "        model.fit(train_x_cv, train_y_cv, epochs=10, batch_size=batch_size, validation_data=(val_x_cv, val_y_cv), verbose=0)\n",
        "\n",
        "    val_loss = model.evaluate(val_x_cv, val_y_cv, verbose=0)\n",
        "    return val_loss\n",
        "\n",
        "# Optuna study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "\n",
        "# Training the model with best hyperparameters on full data\n",
        "best_params = study.best_params\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=best_params[\"lstm_units\"], return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
        "model.add(Dropout(best_params[\"dropout_rate\"]))\n",
        "model.add(LSTM(units=best_params[\"lstm_units\"]))\n",
        "model.add(Dropout(best_params[\"dropout_rate\"]))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"]), loss=\"mean_squared_error\")\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=best_params[\"batch_size\"])\n",
        "\n",
        "# ... (Rest of the code remains the same, for predictions, evaluations, etc.)\n",
        "\n",
        "\n",
        "# Train Model\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=32)\n",
        "\n",
        "# Make Predictions\n",
        "predictions = model.predict(test_x)\n",
        "predictions = close_scaler.inverse_transform(predictions)\n",
        "\n",
        "# Evaluate Model\n",
        "mse = mean_squared_error(predictions, close_scaler.inverse_transform(test_y.reshape(-1, 1)))\n",
        "mae = mean_absolute_error(predictions, close_scaler.inverse_transform(test_y.reshape(-1, 1)))\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Save Model\n",
        "model.save(\"forex_trading_bot_model.keras\")\n",
        "\n",
        "# Make a prediction for the next day\n",
        "next_day_sequence = np.expand_dims(test_x[-1], axis=0)\n",
        "next_day_prediction = model.predict(next_day_sequence)\n",
        "next_day_price = close_scaler.inverse_transform(next_day_prediction)[0][0]\n",
        "\n",
        "# Print the predicted price for the next day\n",
        "print(\"Predicted price for the next day:\", next_day_price)\n",
        "\n",
        "# Determine the action based on the predicted price\n",
        "if next_day_price > df[\"Close\"].iloc[-1]:\n",
        "    print(\"Action: Buy\")\n",
        "elif next_day_price < df[\"Close\"].iloc[-1]:\n",
        "    print(\"Action: Sell\")\n",
        "else:\n",
        "    print(\"Action: Hold\")\n",
        "\n",
        "# Create a baseline model that predicts the last known price as the next day's price\n",
        "baseline_predictions = np.roll(test_x[:,-1,0], -1)  # Shift the last known prices one step forward\n",
        "baseline_mse = mean_squared_error(test_y[:-1], baseline_predictions[:-1])\n",
        "baseline_mae = mean_absolute_error(test_y[:-1], baseline_predictions[:-1])\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) and Mean Absolute Error (MAE) for the LSTM model\n",
        "lstm_mse = mean_squared_error(test_y, predictions)\n",
        "lstm_mae = mean_absolute_error(test_y, predictions)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"\\nBaseline Model:\")\n",
        "print(\"MSE:\", baseline_mse)\n",
        "print(\"MAE:\", baseline_mae)\n",
        "\n",
        "print(\"\\nLSTM Model:\")\n",
        "print(\"MSE:\", lstm_mse)\n",
        "print(\"MAE:\", lstm_mae)\n",
        "\n",
        "# Compare the LSTM model's performance with the baseline model's performance\n",
        "if lstm_mse < baseline_mse and lstm_mae < baseline_mae:\n",
        "    print(\"\\nConclusion: The LSTM model's performance is better than the baseline model. Consider using LSTM predictions for trading forex.\")\n",
        "    if next_day_price > df[\"Close\"].iloc[-1]:\n",
        "        print(\"Action: Buy\")\n",
        "    elif next_day_price < df[\"Close\"].iloc[-1]:\n",
        "        print(\"Action: Sell\")\n",
        "    else:\n",
        "        print(\"Action: Hold\")\n",
        "elif lstm_mse > baseline_mse and lstm_mae > baseline_mae:\n",
        "    print(\"\\nConclusion: The baseline model's performance is better than the LSTM model. Caution advised.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: The LSTM model's performance is similar to the baseline model. Use additional analysis for decision-making.\")"
      ]
    }
  ]
}